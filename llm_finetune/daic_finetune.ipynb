{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WMaAhfOrazZp",
        "outputId": "6e6c5d58-1e5c-466c-8c47-482a0820da97"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CUDA available. GPU: Tesla T4\n",
            "Total GPU memory: 14.74 GB\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import glob, os\n",
        "import pandas as pd\n",
        "import gc\n",
        "from transformers import pipeline\n",
        "from torch.utils.data import Dataset\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from peft import LoraConfig, get_peft_model, TaskType, PeftModel\n",
        "from transformers import TrainingArguments, Trainer, StoppingCriteria, StoppingCriteriaList\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Set CUDA memory allocation to reduce fragmentation\n",
        "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n",
        "\n",
        "# Clear CUDA cache at startup\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.empty_cache()\n",
        "    torch.cuda.ipc_collect()\n",
        "    torch.cuda.synchronize()\n",
        "    print(f\"CUDA available. GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"Total GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vmxs7x2DBTKA",
        "outputId": "cb8e3fa6-eb33-4f42-b3f8-51836b521368"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CDgbraJSBwsR"
      },
      "outputs": [],
      "source": [
        "!unzip /content/drive/MyDrive/daic_data/daic_data.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v20qRAaXf2sR"
      },
      "outputs": [],
      "source": [
        "# !unzip /content/drive/MyDrive/daic_data/tiny_llama_instruction_tuned_old.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h2AGaCQexbCS"
      },
      "source": [
        "## Data processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Php58L8LbQNv"
      },
      "outputs": [],
      "source": [
        "def get_questions_answers_df(transcripts_dir):\n",
        "  transcripts_files = glob.glob(os.path.join(transcripts_dir, \"*.csv\"))\n",
        "\n",
        "  # Load and concatenate all transcript files\n",
        "  df = pd.concat(\n",
        "    (\n",
        "      pd.read_csv(file, sep=\"\\t\", encoding=\"utf-8-sig\").assign(source=os.path.basename(file))\n",
        "      for file in transcripts_files\n",
        "    ),\n",
        "    ignore_index=True\n",
        "  )\n",
        "\n",
        "  # Create block_id to identify contiguous speaker segments\n",
        "  df['block_id'] = (df['speaker'] != df['speaker'].shift(1)).cumsum()\n",
        "\n",
        "  # Aggregate by source and block_id to merge contiguous segments by the same speaker\n",
        "  df = df.groupby(['source', 'block_id']).agg(\n",
        "    speaker=('speaker', 'first'),\n",
        "    start_time=('start_time', 'min'),\n",
        "    stop_time=('stop_time', 'max'),\n",
        "    value=('value', lambda x: ' '.join(x.astype(str)))\n",
        "  )\n",
        "\n",
        "  # Sort by participant and time\n",
        "  df = df.sort_values(by=['source', 'start_time']).reset_index()\n",
        "\n",
        "  # Add previous speaker and value columns only if the previous source is the same\n",
        "  df['prev_speaker'] = df.groupby('source')['speaker'].shift(1)\n",
        "  df['prev_value'] = df.groupby('source')['value'].shift(1)\n",
        "\n",
        "  is_answer = (\n",
        "    (df['speaker'] == 'Participant') &\n",
        "    (df['prev_speaker'] == 'Ellie') &\n",
        "    (df['source'] == df['source'].shift(1))\n",
        "  )\n",
        "\n",
        "  df = df[is_answer].copy()\n",
        "  df = df.rename(columns={\n",
        "    'prev_value': 'question', # The previous Ellie utterance is the question\n",
        "    'value': 'answer',            # The current Participant utterance is the answer\n",
        "  })\n",
        "\n",
        "  df['participant_id'] = df['source'].str.split(\"_\").str[0].astype(int)\n",
        "  df = df[['participant_id', 'question', 'answer', 'start_time']]\n",
        "\n",
        "  return df\n",
        "\n",
        "def add_labels_to_df(qa_df, labels_dir):\n",
        "  splits = ['train', 'dev', 'test']\n",
        "\n",
        "  all_labels_df = pd.DataFrame()\n",
        "  for split in splits:\n",
        "    split_labels_df = pd.read_csv(os.path.join(labels_dir, f\"{split}.csv\"))\n",
        "    split_labels_df = split_labels_df.rename(columns={\n",
        "      \"Participant_ID\": \"participant_id\",\n",
        "      \"PHQ8_Binary\": \"depression_label\",\n",
        "      \"PHQ8_Score\": \"depression_severity\",\n",
        "      \"PHQ_Binary\": \"depression_label\",\n",
        "      \"PHQ_Score\": \"depression_severity\",\n",
        "    })\n",
        "    split_labels_df = split_labels_df[[\"participant_id\", \"depression_label\", \"depression_severity\"]]\n",
        "    split_labels_df[\"split\"] = split\n",
        "    all_labels_df = pd.concat([all_labels_df, split_labels_df], ignore_index=True)\n",
        "\n",
        "  merged_df = pd.merge(qa_df, all_labels_df, on=\"participant_id\", how=\"left\")\n",
        "  return merged_df\n",
        "\n",
        "def format_input(df, row, n_context=3):\n",
        "  past_pairs = df[\n",
        "    (df['participant_id'] == row['participant_id']) &\n",
        "    (df.index < row.name)\n",
        "  ].tail(n_context)\n",
        "\n",
        "  context_lines = []\n",
        "  for _, past_row in past_pairs.iterrows():\n",
        "    q = str(past_row.get(\"question\", \"\")).strip()\n",
        "    a = str(past_row.get(\"answer\", \"\")).strip()\n",
        "    context_lines.append(f\"Q: {q}\\nA: {a}\")\n",
        "\n",
        "  context = \"[START]\\n\" + \"\\n\".join(context_lines) if context_lines else \"[START]\\n\"\n",
        "\n",
        "  instruction = (\n",
        "    \"### Instruction:\\n\"\n",
        "    \"You are analyzing a therapeutic interview between a virtual interviewer (Ellie) and a participant.\\n\"\n",
        "    \"The participant has a PHQ-8 score ranging from 0 (no depression) to 24 (severe depression). \"\n",
        "    f\"This participant’s score is {row['depression_severity']}. \"\n",
        "    \"Scores of 10 or higher are typically considered indicative of depression.\\n\"\n",
        "    \"Given the participant’s previous responses and their PHQ score, \"\n",
        "    \"predict how they might answer the next question in a coherent and realistic way. \"\n",
        "    \"Use natural, casual language. Avoid overly formal styles. \"\n",
        "    \"Tolerate some irregularities (omissions, repetitions, filler words).\\n\\n\"\n",
        "  )\n",
        "\n",
        "  question = str(row.get(\"question\", \"\")).strip()\n",
        "\n",
        "  input_text = f\"### Input:\\n{context}\\nQ: {question}\\nA:\"\n",
        "\n",
        "  return instruction + input_text\n",
        "\n",
        "class InstructionDataset(Dataset):\n",
        "    def __init__(self, dataframe, tokenizer, max_length=512):\n",
        "        dataframe = dataframe.sort_values(\n",
        "            by=['participant_id', 'start_time']\n",
        "        ).reset_index(drop=True)\n",
        "\n",
        "        self.df = dataframe\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "        self.samples = []\n",
        "\n",
        "        # Filter out empty responses to prevent NaN loss\n",
        "        skipped = 0\n",
        "        for _, row in self.df.iterrows():\n",
        "            response = str(row.get(\"answer\", \"\")).strip()\n",
        "\n",
        "            # Skip empty or very short responses (less than 3 characters)\n",
        "            if not response or len(response) < 3:\n",
        "                skipped += 1\n",
        "                continue\n",
        "\n",
        "            prompt = format_input(self.df, row)\n",
        "            full = f\"{prompt}\\n\\n### Response:\\n{response} [END]\"\n",
        "            self.samples.append((prompt, full))\n",
        "\n",
        "        if skipped > 0:\n",
        "            print(f\"Warning: Skipped {skipped} samples with empty or very short responses\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        prompt, full_text = self.samples[idx]\n",
        "\n",
        "        encoded_full = self.tokenizer(\n",
        "            full_text,\n",
        "            truncation=True,\n",
        "            padding=\"max_length\",\n",
        "            max_length=self.max_length,\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "\n",
        "        encoded_prompt = self.tokenizer(\n",
        "            prompt,\n",
        "            truncation=True,\n",
        "            padding=\"max_length\",\n",
        "            max_length=self.max_length,\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "\n",
        "        input_ids = encoded_full[\"input_ids\"].squeeze(0)\n",
        "        attention_mask = encoded_full[\"attention_mask\"].squeeze(0)\n",
        "\n",
        "        prompt_len = (encoded_prompt[\"input_ids\"] != self.tokenizer.pad_token_id).sum()\n",
        "\n",
        "        labels = input_ids.clone()\n",
        "        labels[:prompt_len] = -100  # ignore instruction & input tokens\n",
        "\n",
        "        # Validate that we have at least some non-ignored labels\n",
        "        # This prevents NaN loss when all labels are -100\n",
        "        valid_labels = (labels != -100).sum().item()\n",
        "        if valid_labels == 0:\n",
        "            # If somehow all labels are -100, this is a problem\n",
        "            # Find the first non-pad token after prompt_len and make it a valid label\n",
        "            for i in range(prompt_len, len(input_ids)):\n",
        "                if input_ids[i] != self.tokenizer.pad_token_id:\n",
        "                    labels[i] = input_ids[i]\n",
        "                    break\n",
        "            # If still no valid labels (all padding), use EOS token\n",
        "            if (labels != -100).sum().item() == 0:\n",
        "                labels[-1] = self.tokenizer.eos_token_id\n",
        "\n",
        "        return {\n",
        "            \"input_ids\": input_ids,\n",
        "            \"labels\": labels,\n",
        "            \"attention_mask\": attention_mask\n",
        "        }\n",
        "\n",
        "def load_daic_data(tokenizer, data_dir=\"./daic_data/\", should_create_csv=False, return_splits=False):\n",
        "  \"\"\"Load DAIC data and optionally return train/validation/test splits.\n",
        "\n",
        "  Args:\n",
        "    tokenizer: Tokenizer instance\n",
        "    data_dir: Directory containing data\n",
        "    should_create_csv: Whether to save CSV file\n",
        "    return_splits: If True, return train, validation, and test datasets separately\n",
        "\n",
        "  Returns:\n",
        "    If return_splits=False: single InstructionDataset with all data\n",
        "    If return_splits=True: tuple of (train_dataset, val_dataset, test_dataset)\n",
        "  \"\"\"\n",
        "  transcripts_dir = os.path.join(data_dir, \"transcripts\")\n",
        "  labels_dir = os.path.join(data_dir, \"labels\")\n",
        "\n",
        "  qa_df = get_questions_answers_df(transcripts_dir)\n",
        "  qa_df = add_labels_to_df(qa_df, labels_dir)\n",
        "\n",
        "  # Filter out rows with missing depression_severity (NaN values cause NaN loss)\n",
        "  initial_count = len(qa_df)\n",
        "  qa_df = qa_df.dropna(subset=['depression_severity']).copy()\n",
        "  filtered_count = len(qa_df)\n",
        "\n",
        "  if initial_count != filtered_count:\n",
        "    print(f\"Warning: Filtered out {initial_count - filtered_count} rows with missing depression_severity\")\n",
        "\n",
        "  # Ensure depression_severity is numeric\n",
        "  qa_df['depression_severity'] = pd.to_numeric(qa_df['depression_severity'], errors='coerce')\n",
        "  qa_df = qa_df.dropna(subset=['depression_severity']).copy()\n",
        "\n",
        "  if should_create_csv:\n",
        "    qa_df.to_csv(\"questions_and_answers.csv\", index=False, encoding=\"utf-8-sig\")\n",
        "\n",
        "  if return_splits:\n",
        "    # Split into train, validation (dev), and test\n",
        "    train_df = qa_df[qa_df['split'] == 'train'].copy()\n",
        "    val_df = qa_df[qa_df['split'] == 'dev'].copy()\n",
        "    test_df = qa_df[qa_df['split'] == 'test'].copy()\n",
        "\n",
        "    # Additional validation: ensure we have data in all splits\n",
        "    if len(train_df) == 0:\n",
        "      raise ValueError(\"Train dataset is empty after filtering!\")\n",
        "    if len(val_df) == 0:\n",
        "      raise ValueError(\"Validation dataset is empty after filtering! Check if 'dev' split exists in labels.\")\n",
        "    if len(test_df) == 0:\n",
        "      raise ValueError(\"Test dataset is empty after filtering! Check if 'test' split exists in labels.\")\n",
        "\n",
        "    # Check for NaN values in splits\n",
        "    train_nan = train_df['depression_severity'].isna().sum()\n",
        "    val_nan = val_df['depression_severity'].isna().sum()\n",
        "    test_nan = test_df['depression_severity'].isna().sum()\n",
        "\n",
        "    if train_nan > 0:\n",
        "      print(f\"Warning: {train_nan} train samples still have NaN depression_severity\")\n",
        "      train_df = train_df.dropna(subset=['depression_severity']).copy()\n",
        "    if val_nan > 0:\n",
        "      print(f\"Warning: {val_nan} validation samples still have NaN depression_severity\")\n",
        "      val_df = val_df.dropna(subset=['depression_severity']).copy()\n",
        "    if test_nan > 0:\n",
        "      print(f\"Warning: {test_nan} test samples still have NaN depression_severity\")\n",
        "      test_df = test_df.dropna(subset=['depression_severity']).copy()\n",
        "\n",
        "    # Filter out empty answers before creating datasets\n",
        "    train_df = train_df[train_df['answer'].astype(str).str.strip().str.len() >= 3].copy()\n",
        "    val_df = val_df[val_df['answer'].astype(str).str.strip().str.len() >= 3].copy()\n",
        "    test_df = test_df[test_df['answer'].astype(str).str.strip().str.len() >= 3].copy()\n",
        "\n",
        "    print(f\"After filtering empty answers - Train: {len(train_df)}, Val: {len(val_df)}, Test: {len(test_df)}\")\n",
        "\n",
        "    train_dataset = InstructionDataset(train_df, tokenizer)\n",
        "    val_dataset = InstructionDataset(val_df, tokenizer)\n",
        "    test_dataset = InstructionDataset(test_df, tokenizer)\n",
        "\n",
        "    print(f\"Train samples: {len(train_dataset)}\")\n",
        "    print(f\"Validation samples: {len(val_dataset)}\")\n",
        "    print(f\"Test samples: {len(test_dataset)}\")\n",
        "\n",
        "    if len(val_dataset) == 0:\n",
        "      raise ValueError(\"Validation dataset is empty! Cannot proceed with validation.\")\n",
        "    if len(test_dataset) == 0:\n",
        "      raise ValueError(\"Test dataset is empty! Cannot proceed with test evaluation.\")\n",
        "\n",
        "    return train_dataset, val_dataset, test_dataset\n",
        "  else:\n",
        "    instruction_dataset = InstructionDataset(qa_df, tokenizer)\n",
        "    return instruction_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ti-ju1PKbEyH"
      },
      "outputs": [],
      "source": [
        "def get_tokenizer_and_early_model(model_name=\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"):\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "    if tokenizer.pad_token is None:\n",
        "        tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "    # Add [END] as a special token\n",
        "    special_tokens_dict = {\"additional_special_tokens\": [\"[END]\"]}\n",
        "    tokenizer.add_special_tokens(special_tokens_dict)\n",
        "\n",
        "    model = AutoModelForCausalLM.from_pretrained(\n",
        "        model_name,\n",
        "        load_in_8bit=False,\n",
        "        device_map=\"auto\"\n",
        "    )\n",
        "\n",
        "    # Resize token embeddings to accommodate the new [END] token\n",
        "    model.resize_token_embeddings(len(tokenizer))\n",
        "\n",
        "    model.config.pad_token_id = tokenizer.pad_token_id\n",
        "\n",
        "    return tokenizer, model, model_name\n",
        "\n",
        "def get_lora_model(model):\n",
        "  lora_config = LoraConfig(\n",
        "    r=8, # rank\n",
        "    lora_alpha=16,\n",
        "    target_modules=[\"q_proj\", \"v_proj\"], # depends on model architecture\n",
        "    lora_dropout=0.05,\n",
        "    bias=\"none\",\n",
        "    task_type=TaskType.CAUSAL_LM\n",
        "  )\n",
        "\n",
        "  model = get_peft_model(model, lora_config)\n",
        "\n",
        "  # Note: Gradient checkpointing with PEFT can be tricky\n",
        "  # We'll let TrainingArguments handle it if needed\n",
        "  # For now, we'll disable it to avoid the \"no requires_grad\" error\n",
        "\n",
        "  # Ensure model is in train mode\n",
        "  model.train()\n",
        "\n",
        "  # Verify that LoRA parameters have requires_grad=True\n",
        "  trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "  print(f\"Trainable parameters: {trainable_params:,}\")\n",
        "\n",
        "  model.print_trainable_parameters()\n",
        "  return model\n",
        "\n",
        "def validate_dataset(dataset, tokenizer, name=\"dataset\", sample_size=10):\n",
        "    \"\"\"Validate that a dataset has valid labels and won't cause NaN loss.\n",
        "\n",
        "    Args:\n",
        "        dataset: Dataset to validate\n",
        "        tokenizer: Tokenizer instance\n",
        "        name: Name of dataset for logging\n",
        "        sample_size: Number of samples to check\n",
        "    \"\"\"\n",
        "    print(f\"\\nValidating {name}...\")\n",
        "    invalid_samples = []\n",
        "\n",
        "    for i in range(min(sample_size, len(dataset))):\n",
        "        sample = dataset[i]\n",
        "        labels = sample[\"labels\"]\n",
        "        valid_labels = (labels != -100).sum().item()\n",
        "\n",
        "        if valid_labels == 0:\n",
        "            invalid_samples.append(i)\n",
        "            print(f\"  Warning: Sample {i} has no valid labels (all -100)\")\n",
        "\n",
        "    if invalid_samples:\n",
        "        print(f\"  Found {len(invalid_samples)} invalid samples in first {sample_size} samples\")\n",
        "        print(f\"  This may cause NaN validation loss!\")\n",
        "    else:\n",
        "        print(f\"  ✓ All {sample_size} checked samples have valid labels\")\n",
        "\n",
        "    return len(invalid_samples) == 0\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    \"\"\"Compute metrics for evaluation, handling NaN values gracefully.\"\"\"\n",
        "    import numpy as np\n",
        "    predictions, labels = eval_pred\n",
        "\n",
        "    # Handle NaN in predictions\n",
        "    if isinstance(predictions, tuple):\n",
        "        predictions = predictions[0]\n",
        "\n",
        "    # Check for NaN values\n",
        "    if np.isnan(predictions).any():\n",
        "        print(\"Warning: NaN values detected in predictions during evaluation\")\n",
        "        predictions = np.nan_to_num(predictions, nan=0.0)\n",
        "\n",
        "    # For language modeling, we typically just return a dummy metric\n",
        "    # The actual loss is computed by the model\n",
        "    return {\"eval_loss\": 0.0}  # Dummy return, actual loss comes from model\n",
        "\n",
        "def fine_tune_model(\n",
        "    model,\n",
        "    tokenizer,\n",
        "    train_dataset,\n",
        "    output_dir=\"./tiny_llama_instruction_tuned\",\n",
        "    eval_dataset=None,\n",
        "    test_dataset=None,\n",
        "):\n",
        "    \"\"\"Fine-tune model with optional validation and test datasets.\n",
        "\n",
        "    Args:\n",
        "        model: Model to fine-tune\n",
        "        tokenizer: Tokenizer instance\n",
        "        train_dataset: Training dataset\n",
        "        output_dir: Output directory for checkpoints\n",
        "        eval_dataset: Optional validation dataset for monitoring during training\n",
        "        test_dataset: Optional test dataset for final evaluation after training\n",
        "    \"\"\"\n",
        "\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir=output_dir,\n",
        "        per_device_train_batch_size=2,\n",
        "        per_device_eval_batch_size=2,\n",
        "        gradient_accumulation_steps=4,\n",
        "        eval_accumulation_steps=4,\n",
        "        warmup_steps=50,\n",
        "        num_train_epochs=1,\n",
        "        learning_rate=1e-4,\n",
        "        lr_scheduler_type=\"cosine\",  # Use cosine learning rate schedule\n",
        "        fp16=True,\n",
        "        logging_steps=50,\n",
        "        save_steps=200,\n",
        "        eval_strategy=\"steps\" if eval_dataset else \"no\",  # Enable evaluation during training\n",
        "        eval_steps=200,  # Evaluate every 200 steps\n",
        "        save_total_limit=3,\n",
        "        load_best_model_at_end=True if eval_dataset else False,  # Load best model based on eval loss\n",
        "        metric_for_best_model=\"eval_loss\" if eval_dataset else None,\n",
        "        greater_is_better=False,  # Lower loss is better\n",
        "        max_grad_norm=1.0,  # Gradient clipping to prevent exploding gradients\n",
        "        dataloader_pin_memory=False,  # Disable pinning to save memory\n",
        "        remove_unused_columns=False,  # Keep all columns for debugging\n",
        "        report_to=\"none\",  # Disable wandb/tensorboard to avoid issues\n",
        "        dataloader_num_workers=0,  # Disable multiprocessing to save memory\n",
        "        prediction_loss_only=True,  # Only compute loss during eval, don't store predictions (saves memory)\n",
        "    )\n",
        "\n",
        "    # Ensure model is in train mode before training\n",
        "    model.train()\n",
        "\n",
        "    def collator(batch):\n",
        "        # Validate batch before returning\n",
        "        batch_dict = {\n",
        "            \"input_ids\": torch.stack([x[\"input_ids\"] for x in batch]),\n",
        "            \"labels\": torch.stack([x[\"labels\"] for x in batch]),\n",
        "            \"attention_mask\": torch.stack([x[\"attention_mask\"] for x in batch]),\n",
        "        }\n",
        "\n",
        "        # Check for samples with no valid labels (all -100) and fix them\n",
        "        labels = batch_dict[\"labels\"]\n",
        "        input_ids = batch_dict[\"input_ids\"]\n",
        "        fixed_count = 0\n",
        "\n",
        "        for i in range(len(batch)):\n",
        "            valid_labels = (labels[i] != -100).sum().item()\n",
        "            if valid_labels == 0:\n",
        "                fixed_count += 1\n",
        "                # Make at least one label valid to prevent NaN\n",
        "                # Find first non-pad token and make it a valid label\n",
        "                for j in range(len(labels[i])):\n",
        "                    if input_ids[i][j] != tokenizer.pad_token_id:\n",
        "                        labels[i][j] = input_ids[i][j]\n",
        "                        break\n",
        "                # If still all padding, use EOS token\n",
        "                if (labels[i] != -100).sum().item() == 0:\n",
        "                    labels[i][-1] = tokenizer.eos_token_id\n",
        "\n",
        "        if fixed_count > 0:\n",
        "            print(f\"Warning: Fixed {fixed_count} samples in batch with no valid labels\")\n",
        "\n",
        "        return batch_dict\n",
        "\n",
        "    # Validate datasets before training\n",
        "    print(\"\\nValidating datasets before training...\")\n",
        "    validate_dataset(train_dataset, tokenizer, \"train_dataset\", sample_size=20)\n",
        "    if eval_dataset:\n",
        "        validate_dataset(eval_dataset, tokenizer, \"eval_dataset\", sample_size=20)\n",
        "    if test_dataset:\n",
        "        validate_dataset(test_dataset, tokenizer, \"test_dataset\", sample_size=20)\n",
        "\n",
        "    # Create a custom Trainer that clears memory before evaluation\n",
        "    class MemoryEfficientTrainer(Trainer):\n",
        "        def evaluate(self, eval_dataset=None, ignore_keys=None, metric_key_prefix=\"eval\"):\n",
        "            # Clear memory before evaluation\n",
        "            clear_memory()\n",
        "            return super().evaluate(eval_dataset, ignore_keys, metric_key_prefix)\n",
        "\n",
        "    trainer = MemoryEfficientTrainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=train_dataset,\n",
        "        eval_dataset=eval_dataset,\n",
        "        data_collator=collator,\n",
        "        compute_metrics=compute_metrics if eval_dataset else None,\n",
        "    )\n",
        "\n",
        "    trainer.train()\n",
        "\n",
        "    # Evaluate on test dataset after training if provided\n",
        "    # if test_dataset:\n",
        "    #     print(\"\\n\" + \"=\" * 80)\n",
        "    #     print(\"EVALUATING ON TEST DATASET\")\n",
        "    #     print(\"=\" * 80)\n",
        "    #     clear_memory()\n",
        "\n",
        "    #     # Evaluate on test set\n",
        "    #     test_metrics = trainer.evaluate(eval_dataset=test_dataset, metric_key_prefix=\"test\")\n",
        "\n",
        "    #     print(\"\\nTest Dataset Results:\")\n",
        "    #     for key, value in test_metrics.items():\n",
        "    #         print(f\"  {key}: {value:.4f}\")\n",
        "\n",
        "    #     clear_memory()\n",
        "\n",
        "    model.save_pretrained(output_dir)\n",
        "    tokenizer.save_pretrained(output_dir)\n",
        "\n",
        "def use_tokenizer(tokenizer, text):\n",
        "  return tokenizer(text, truncation=True, padding='max_length', max_length=512)\n",
        "\n",
        "# Stopping criteria for [END] token\n",
        "class EndTokenStoppingCriteria(StoppingCriteria):\n",
        "    def __init__(self, end_token_id, min_tokens=5):\n",
        "        self.end_token_id = end_token_id\n",
        "        self.min_tokens = min_tokens  # Minimum tokens to generate before allowing stop\n",
        "        self.initial_length = None\n",
        "\n",
        "    def __call__(self, input_ids, scores, **kwargs):\n",
        "        # Stop if the last generated token is [END]\n",
        "        # input_ids is a tensor of shape [batch_size, sequence_length]\n",
        "        # Check the last token of the first (and only) sequence\n",
        "        if input_ids.shape[0] > 0 and input_ids.shape[1] > 0:\n",
        "            # Track initial length on first call\n",
        "            if self.initial_length is None:\n",
        "                self.initial_length = input_ids.shape[1]\n",
        "\n",
        "            # Calculate how many new tokens have been generated\n",
        "            new_tokens_count = input_ids.shape[1] - self.initial_length\n",
        "\n",
        "            # Only stop on [END] if we've generated at least min_tokens\n",
        "            if new_tokens_count >= self.min_tokens:\n",
        "                return input_ids[0][-1].item() == self.end_token_id\n",
        "        return False\n",
        "\n",
        "def create_stopping_criteria(tokenizer, min_tokens=5):\n",
        "    \"\"\"Create stopping criteria that stops at [END] token.\n",
        "\n",
        "    Args:\n",
        "        tokenizer: Tokenizer instance\n",
        "        min_tokens: Minimum number of tokens to generate before allowing stop (default: 5)\n",
        "    \"\"\"\n",
        "    try:\n",
        "        end_token_id = tokenizer.convert_tokens_to_ids(\"[END]\")\n",
        "        if end_token_id is None or end_token_id == tokenizer.unk_token_id:\n",
        "            print(\"Warning: [END] token not found in tokenizer. Stopping criteria will not work correctly.\")\n",
        "            print(f\"Available special tokens: {tokenizer.special_tokens_map}\")\n",
        "            # Fallback: use EOS token instead\n",
        "            end_token_id = tokenizer.eos_token_id\n",
        "            print(f\"Using EOS token ({end_token_id}) as fallback for stopping criteria.\")\n",
        "        return StoppingCriteriaList([EndTokenStoppingCriteria(end_token_id, min_tokens=min_tokens)])\n",
        "    except Exception as e:\n",
        "        print(f\"Error creating stopping criteria: {e}\")\n",
        "        # Fallback: use EOS token\n",
        "        end_token_id = tokenizer.eos_token_id\n",
        "        return StoppingCriteriaList([EndTokenStoppingCriteria(end_token_id, min_tokens=min_tokens)])\n",
        "\n",
        "def clear_memory():\n",
        "    \"\"\"Clear GPU and CPU memory cache.\"\"\"\n",
        "    gc.collect()\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "        torch.cuda.synchronize()\n",
        "\n",
        "def load_finetuned_model(model_name, tokenizer, checkpoint_path=None):\n",
        "    \"\"\"Load a finetuned model from checkpoint or final model.\n",
        "    Note: Base model is loaded fresh each time to avoid PEFT weight conflicts.\n",
        "\n",
        "    Args:\n",
        "        model_name: Base model name\n",
        "        tokenizer: Tokenizer instance\n",
        "        checkpoint_path: Path to checkpoint, or None for final model\n",
        "    \"\"\"\n",
        "    # Determine device\n",
        "    device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "    print(f\"Device set to use {device}\")\n",
        "\n",
        "    # Always load base model fresh to avoid PEFT weight conflicts\n",
        "    # (PEFT models modify base model in place, so we can't reuse it)\n",
        "    # Use explicit device placement instead of device_map=\"auto\" to avoid multi-device issues\n",
        "    base = AutoModelForCausalLM.from_pretrained(\n",
        "        model_name,\n",
        "        torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,\n",
        "        device_map=None  # Don't use device_map to avoid offloading issues\n",
        "    )\n",
        "\n",
        "    # Manually move to device\n",
        "    base = base.to(device)\n",
        "\n",
        "    # Resize token embeddings if [END] token was added\n",
        "    if len(tokenizer) != base.get_input_embeddings().weight.shape[0]:\n",
        "        base.resize_token_embeddings(len(tokenizer))\n",
        "\n",
        "    if checkpoint_path:\n",
        "        lora = PeftModel.from_pretrained(base, checkpoint_path, device_map=None)\n",
        "    else:\n",
        "        lora = PeftModel.from_pretrained(base, \"./tiny_llama_instruction_tuned\", device_map=None)\n",
        "\n",
        "    # Ensure model is on the correct device\n",
        "    lora = lora.to(device)\n",
        "\n",
        "    # Set model to eval mode for proper inference behavior\n",
        "    lora.eval()\n",
        "    print(\"Model set to eval mode for inference\")\n",
        "\n",
        "    return lora, base  # Return both so we can clean up base separately\n",
        "\n",
        "def generate_response(model, tokenizer, prompt, max_new_tokens=100, stopping_criteria=None,\n",
        "                      do_sample=True, temperature=0.7, top_p=0.9, top_k=50, repetition_penalty=1.1):\n",
        "    \"\"\"Generate a response using the model. Cleans up pipeline after use.\n",
        "\n",
        "    Args:\n",
        "        model: Model to use for generation\n",
        "        tokenizer: Tokenizer instance\n",
        "        prompt: Input prompt\n",
        "        max_new_tokens: Maximum number of tokens to generate\n",
        "        stopping_criteria: Optional stopping criteria\n",
        "        do_sample: Whether to use sampling (default: True)\n",
        "        temperature: Sampling temperature (default: 0.7)\n",
        "        top_p: Nucleus sampling parameter (default: 0.9)\n",
        "        top_k: Top-k sampling parameter (default: 50)\n",
        "        repetition_penalty: Repetition penalty (default: 1.1)\n",
        "    \"\"\"\n",
        "    pipe = None\n",
        "    try:\n",
        "        pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n",
        "\n",
        "        if stopping_criteria is None:\n",
        "            stopping_criteria = create_stopping_criteria(tokenizer)\n",
        "\n",
        "        # Print generation parameters for debugging\n",
        "        print(f\"Generating with parameters: do_sample={do_sample}, temperature={temperature}, top_p={top_p}, top_k={top_k}\")\n",
        "        print(f\"Input prompt length: {len(prompt)} characters\")\n",
        "\n",
        "        # Tokenize prompt to check input\n",
        "        input_ids = tokenizer(prompt, return_tensors=\"pt\")[\"input_ids\"]\n",
        "        print(f\"Input token IDs shape: {input_ids.shape}\")\n",
        "        print(f\"Input token IDs (first 20): {input_ids[0][:20].tolist()}\")\n",
        "\n",
        "        # Generate with proper parameters\n",
        "        res = pipe(\n",
        "            prompt,\n",
        "            max_new_tokens=max_new_tokens,\n",
        "            stopping_criteria=stopping_criteria,\n",
        "            do_sample=do_sample,\n",
        "            temperature=temperature,\n",
        "            top_p=top_p,\n",
        "            top_k=top_k,\n",
        "            repetition_penalty=repetition_penalty,\n",
        "            pad_token_id=tokenizer.pad_token_id,\n",
        "            eos_token_id=tokenizer.eos_token_id,\n",
        "            return_full_text=True\n",
        "        )\n",
        "\n",
        "        generated_text = res[0][\"generated_text\"]\n",
        "\n",
        "        # Debug: Check generated tokens\n",
        "        full_ids = tokenizer(generated_text, return_tensors=\"pt\")[\"input_ids\"]\n",
        "        new_tokens = full_ids[0][input_ids.shape[1]:]\n",
        "        print(f\"Generated token IDs shape: {new_tokens.shape}\")\n",
        "        print(f\"Generated token IDs (first 20): {new_tokens[:20].tolist()}\")\n",
        "        print(f\"Full generated text length: {len(generated_text)} characters\")\n",
        "        print(f\"Full generated text (first 200 chars): {generated_text[:200]}\")\n",
        "\n",
        "        return generated_text\n",
        "    finally:\n",
        "        # Clean up pipeline\n",
        "        if pipe is not None:\n",
        "            del pipe\n",
        "        clear_memory()\n",
        "\n",
        "def extract_response_only(full_output, prompt):\n",
        "    \"\"\"Extract only the generated response part, removing the prompt.\"\"\"\n",
        "    if full_output.startswith(prompt):\n",
        "        return full_output[len(prompt):].strip()\n",
        "    return full_output\n",
        "\n",
        "def unload_model(model):\n",
        "    \"\"\"Unload a model from memory.\"\"\"\n",
        "    if model is not None:\n",
        "        # Move to CPU and delete\n",
        "        if hasattr(model, 'cpu'):\n",
        "            model.cpu()\n",
        "        del model\n",
        "        clear_memory()\n",
        "\n",
        "def evaluate_model_on_test(model, tokenizer, test_dataset, output_dir=\"./tiny_llama_instruction_tuned\"):\n",
        "    \"\"\"Evaluate a model on the test dataset and return metrics.\n",
        "\n",
        "    Args:\n",
        "        model: Model to evaluate\n",
        "        tokenizer: Tokenizer instance\n",
        "        test_dataset: Test dataset\n",
        "        output_dir: Output directory for training args (needed for Trainer)\n",
        "\n",
        "    Returns:\n",
        "        Dictionary of test metrics\n",
        "    \"\"\"\n",
        "    from transformers import TrainingArguments, Trainer\n",
        "\n",
        "    # Create minimal training args for evaluation\n",
        "    eval_args = TrainingArguments(\n",
        "        output_dir=output_dir,\n",
        "        per_device_eval_batch_size=1,\n",
        "        eval_accumulation_steps=4,\n",
        "        fp16=True,\n",
        "        dataloader_num_workers=0,\n",
        "        prediction_loss_only=True,\n",
        "        report_to=\"none\",\n",
        "    )\n",
        "\n",
        "    def collator(batch):\n",
        "        return {\n",
        "            \"input_ids\": torch.stack([x[\"input_ids\"] for x in batch]),\n",
        "            \"labels\": torch.stack([x[\"labels\"] for x in batch]),\n",
        "            \"attention_mask\": torch.stack([x[\"attention_mask\"] for x in batch]),\n",
        "        }\n",
        "\n",
        "    # Create trainer for evaluation\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=eval_args,\n",
        "        data_collator=collator,\n",
        "        compute_metrics=compute_metrics,\n",
        "    )\n",
        "\n",
        "    # Evaluate on test set\n",
        "    clear_memory()\n",
        "    test_metrics = trainer.evaluate(eval_dataset=test_dataset, metric_key_prefix=\"test\")\n",
        "    clear_memory()\n",
        "\n",
        "    return test_metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "e22024bc36d241f1ba4187ea75d20d9a",
            "5bde957c7fa5405c82621755bb8e99a5",
            "56e29613e37149be895a93c755baa783",
            "89570a3fce394ddd81c5a5eb1f2c7cbb",
            "b73f30ac75324c878fd202825ff051b0",
            "cbc3f0acbd044f35a06fc5ec031b7a13",
            "382743f38f304d8a92b8f3be6ad8accb",
            "5e4f97d1db7c4501abc67840dd754fca",
            "d0dd00a7fb054c47a771f77e699ec106",
            "294ca0b317fc40448615a93957456df3",
            "bacc327e99bd4030bf721d40a2270178",
            "76ad1c63a59a4e0598d477d2378e2ff3",
            "1347cdbf28ca4b8283762144e80498e4",
            "92e4f2b6b4f4472c811dc2dfa88fb073",
            "b09b7e73032e44a0a676229c752264ce",
            "cfef698890dd4efdae358c5cb449b480",
            "d9bbfe584a814d51b0081c2f6d596c49",
            "3d9d8fa5501c4b64bc3a56a9de0778b1",
            "d94ccb2e46a34fc497b5a0ea7094b555",
            "864b0312be704218a0d67ffa3f668296",
            "b6dcc7166be6428396e06b1de5a22fb0",
            "3e2708494e2a442fab323756f4614b96",
            "56fb8ea45bae4768ae8b3935eb313437",
            "2bc9b2e8fff044e5b99d4a6a0dba8c41",
            "f37660376c1843ac93929591e331a4c3",
            "fd49caa736c043e3a013db50537f0d17",
            "30dc97bcc5e649bea85664945475255b",
            "a3315c72e2e645afb87719cb775bf9a4",
            "d2fa92921d474e94880573aff86543e1",
            "f8f9bddf00604b35964c9a132e2119a1",
            "299e8325eeed4b27ad9eb9f1ac172c08",
            "907923f82c0e4535a40b064fabd47a56",
            "b78f81b677764140ac6e8f91b93cd931",
            "d8d0c877b25f4353aab7329825eb4436",
            "10f271c542cd4b48a675e5eece779288",
            "01ad24b99b7b4e0bb99bb5dc6b0b88e1",
            "c66abb85c5d745509303452122f39834",
            "25a9f9000f6941e48a3e289b6b163eed",
            "ad8d36a18ea942b59f804d0955cf446c",
            "d3e81969a36f4300aec646c4ceaa07e0",
            "5198ded7b5004e3d88710742580da2ea",
            "bea913c7854e49519d15802c463f7b84",
            "64ef082475b44a05b1681833bebfbf16",
            "c40b888c76fb44bb943ac514fe6f5341",
            "849a279ec86c4945aa042577678d3d73",
            "a0e91409876048698b925cf8e9738bf7",
            "c3e93fd7949440329b7f12e5d829e199",
            "81c7089382194cb69327a673fade34d6",
            "af0a329bcaf84e7995c0700a83862301",
            "6b09687d30da40ba910f1e8236e35292",
            "c8cbf8ff7c5b40de9cdeb919f1841b59",
            "cbe0398706aa44209fc058fbdcb030d0",
            "554c7cb87b894688a879e9439ea1cca6",
            "21a132f36a3349608deb38af4a517237",
            "dd4f5eefc717494b81ca9702dda23379",
            "90bf8182e8694d52822c36735a7015ce",
            "780e75ef9d614625bc4f7734482deeed",
            "7af402bc8f6342f483bb73abe8568439",
            "36639d2f495943c286e751a3d0747780",
            "5c5515a6ec9249f69990aacca4e9d8cb",
            "44a9b8e66fa74581abac66e133b9b4dc",
            "cc0121c3f82e42fa8174e86224eace37",
            "5db33535e9c4489bb6b6bb54cf6ade1b",
            "ee0b9614209144b8ab038863d3537e0c",
            "c000c7f314634e8c82523f77635f7d8b",
            "6e2abba6ce6241e09f5688bff10965af",
            "6c4d97fd6f764f92a479a57880d55608",
            "645bd2170fb348fd828fa58c5a5b93e4",
            "c0d4ce502d7c4457a5aba8b7ac322a68",
            "d20f8bc1859c4ef793a19522936a11f3",
            "2da21a3d9db643a896fde03dcc4b7a3c",
            "be2da52036a0420eb063b2d4e8b03429",
            "c0a0541adb0945fe9e9f83af88eff674",
            "0c2e6a131c334f808eba58cc5b873706",
            "0a367ddbccd448ceb273811c51f2429f",
            "ebf6a692195440f6bf1a0d91cb24dd8f",
            "ee7f858281e24e228b9302eeffcd2712"
          ]
        },
        "id": "ZRzYCDDqbcM6",
        "outputId": "3b78fd8d-96f9-4124-ac91-3d25f74d1620"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "CLEARING GPU MEMORY BEFORE TRAINING\n",
            "================================================================================\n",
            "GPU memory - Total: 14.74 GB, Reserved: 0.00 GB, Free: 14.74 GB\n",
            "\n",
            "Loading tokenizer and model...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e22024bc36d241f1ba4187ea75d20d9a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "76ad1c63a59a4e0598d477d2378e2ff3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "56fb8ea45bae4768ae8b3935eb313437",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d8d0c877b25f4353aab7329825eb4436",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/551 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "849a279ec86c4945aa042577678d3d73",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/608 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "90bf8182e8694d52822c36735a7015ce",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/2.20G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6c4d97fd6f764f92a479a57880d55608",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n",
            "The new lm_head weights will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "After loading model - Allocated: 4.11 GB, Reserved: 4.98 GB\n",
            "\n",
            "Loading datasets (train, validation, and test)...\n",
            "After filtering empty answers - Train: 5953, Val: 1785, Test: 2588\n",
            "Train samples: 5953\n",
            "Validation samples: 1785\n",
            "Test samples: 2588\n",
            "\n",
            "Getting LoRA model...\n",
            "Trainable parameters: 1,126,400\n",
            "trainable params: 1,126,400 || all params: 1,101,178,880 || trainable%: 0.1023\n",
            "After LoRA - Allocated: 4.11 GB, Reserved: 4.98 GB\n",
            "\n",
            "Fine-tuning model with validation monitoring and test evaluation...\n",
            "\n",
            "Validating datasets before training...\n",
            "\n",
            "Validating train_dataset...\n",
            "  ✓ All 20 checked samples have valid labels\n",
            "\n",
            "Validating eval_dataset...\n",
            "  ✓ All 20 checked samples have valid labels\n",
            "\n",
            "Validating test_dataset...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The model is already on multiple devices. Skipping the move to device specified in `args`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  ✓ All 20 checked samples have valid labels\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='745' max='745' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [745/745 30:07, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.423400</td>\n",
              "      <td>1.166789</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.431000</td>\n",
              "      <td>1.002135</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.429000</td>\n",
              "      <td>0.964098</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/peft/utils/save_and_load.py:309: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/peft/utils/save_and_load.py:309: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/peft/utils/save_and_load.py:309: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/peft/utils/save_and_load.py:309: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/peft/utils/save_and_load.py:309: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Clear all memory before starting\n",
        "print('=' * 80)\n",
        "print('CLEARING GPU MEMORY BEFORE TRAINING')\n",
        "print('=' * 80)\n",
        "clear_memory()\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.empty_cache()\n",
        "    torch.cuda.ipc_collect()\n",
        "    total = torch.cuda.get_device_properties(0).total_memory / 1024**3\n",
        "    reserved = torch.cuda.memory_reserved() / 1024**3\n",
        "    free = total - reserved\n",
        "    print(f'GPU memory - Total: {total:.2f} GB, Reserved: {reserved:.2f} GB, Free: {free:.2f} GB')\n",
        "    if free < 8.0:\n",
        "        print(f'\\n⚠️  WARNING: Only {free:.2f} GB free. Consider restarting kernel to clear all memory.')\n",
        "\n",
        "print('\\nLoading tokenizer and model...')\n",
        "tokenizer, model, model_name = get_tokenizer_and_early_model()\n",
        "\n",
        "# Check memory after loading model\n",
        "if torch.cuda.is_available():\n",
        "    allocated = torch.cuda.memory_allocated() / 1024**3\n",
        "    reserved = torch.cuda.memory_reserved() / 1024**3\n",
        "    print(f'After loading model - Allocated: {allocated:.2f} GB, Reserved: {reserved:.2f} GB')\n",
        "\n",
        "print('\\nLoading datasets (train, validation, and test)...')\n",
        "train_dataset, val_dataset, test_dataset = load_daic_data(tokenizer, should_create_csv=False, return_splits=True)\n",
        "\n",
        "print('\\nGetting LoRA model...')\n",
        "model = get_lora_model(model)\n",
        "\n",
        "# Check memory after LoRA\n",
        "if torch.cuda.is_available():\n",
        "    allocated = torch.cuda.memory_allocated() / 1024**3\n",
        "    reserved = torch.cuda.memory_reserved() / 1024**3\n",
        "    print(f'After LoRA - Allocated: {allocated:.2f} GB, Reserved: {reserved:.2f} GB')\n",
        "\n",
        "print('\\nFine-tuning model with validation monitoring and test evaluation...')\n",
        "fine_tune_model(model, tokenizer, train_dataset, eval_dataset=val_dataset, test_dataset=test_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OKS6xfhB1qkV"
      },
      "source": [
        "### Best model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "629sz-qTpTVK"
      },
      "outputs": [],
      "source": [
        "request = \"\"\"\n",
        "You are analyzing a therapeutic interview between a virtual interviewer (Ellie) and a participant.\n",
        "The participant has a PHQ-8 score ranging from 0 (no depression) to 24 (severe depression). This participant’s score is 3. Scores of 10 or higher are typically considered indicative of depression.\n",
        "Given the participant’s previous responses and their PHQ score, predict how they might answer the next question in a coherent and realistic way.Use natural, casual language. Avoid overly formal styles.Tolerate some irregularities (omissions, repetitions, filler words) given the conversational context.\n",
        "\n",
        "### Input:\n",
        "[START]\n",
        "Q: right there are always trade offs in life aren't there\n",
        "A: yeah\n",
        "Q: what made you decide to do that\n",
        "A: so um i think i think my in my life i knew that i there's a lot of things i have <ha> there's more dislikes <laughter> than likes so i kinda narrowed it down to what am i good at and what am i not good at and what am i gonna work well or who who am i gonna work well with and who will i not work well with so i kind of i kinda sorted out and then the list kind of mmm kind of answered itself so\n",
        "Q: that sounds really hard\n",
        "A: no it i don't think it was hard but it was just but i think it was a real reality check and i think it it's kind of a good thing 'cause sometimes trying to conform to doing things that doesn't really fit you doesn't make sense it's like trying to shove a a round peg into a square a square hole and it's like it just no matter how you try to shove it in it's not gonna go in so sometimes it's just might as well go down a path that seems to work better for you\n",
        "Q: right that makes sense what's one of your most memorable experiences\n",
        "\n",
        "### Response:\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "GDH3D2sRAFj4",
        "outputId": "e945b13f-03eb-4ab5-926e-ebabc244083a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`torch_dtype` is deprecated! Use `dtype` instead!\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading final model...\n",
            "Device set to use cuda:0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model set to eval mode for inference\n",
            "\n",
            "Loading test dataset for evaluation...\n",
            "\n",
            "================================================================================\n",
            "EVALUATING FINAL MODEL ON TEST DATASET\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "GENERATING EXAMPLE RESPONSE\n",
            "================================================================================\n",
            "\n",
            "Generating response...\n",
            "Generating with parameters: do_sample=True, temperature=0.7, top_p=0.9, top_k=50\n",
            "Input prompt length: 1697 characters\n",
            "Input token IDs shape: torch.Size([1, 470])\n",
            "Input token IDs (first 20): [1, 29871, 13, 3492, 526, 29537, 292, 263, 266, 1572, 412, 329, 293, 15593, 1546, 263, 6901, 1006, 29894, 15580]\n",
            "Generated token IDs shape: torch.Size([100])\n",
            "Generated token IDs (first 20): [398, 474, 1016, 29915, 29873, 1073, 565, 372, 29915, 29879, 1063, 529, 348, 28327, 29958, 474, 2099, 474, 723, 1827]\n",
            "Full generated text length: 2102 characters\n",
            "Full generated text (first 200 chars): \n",
            "You are analyzing a therapeutic interview between a virtual interviewer (Ellie) and a participant.\n",
            "The participant has a PHQ-8 score ranging from 0 (no depression) to 24 (severe depression). This par\n",
            "================================================================================\n",
            "FULL OUTPUT:\n",
            "================================================================================\n",
            "\n",
            "You are analyzing a therapeutic interview between a virtual interviewer (Ellie) and a participant.\n",
            "The participant has a PHQ-8 score ranging from 0 (no depression) to 24 (severe depression). This participant’s score is 3. Scores of 10 or higher are typically considered indicative of depression.\n",
            "Given the participant’s previous responses and their PHQ score, predict how they might answer the next question in a coherent and realistic way.Use natural, casual language. Avoid overly formal styles.Tolerate some irregularities (omissions, repetitions, filler words) given the conversational context.\n",
            "\n",
            "### Input:\n",
            "[START]\n",
            "Q: right there are always trade offs in life aren't there\n",
            "A: yeah\n",
            "Q: what made you decide to do that\n",
            "A: so um i think i think my in my life i knew that i there's a lot of things i have <ha> there's more dislikes <laughter> than likes so i kinda narrowed it down to what am i good at and what am i not good at and what am i gonna work well or who who am i gonna work well with and who will i not work well with so i kind of i kinda sorted out and then the list kind of mmm kind of answered itself so\n",
            "Q: that sounds really hard\n",
            "A: no it i don't think it was hard but it was just but i think it was a real reality check and i think it it's kind of a good thing 'cause sometimes trying to conform to doing things that doesn't really fit you doesn't make sense it's like trying to shove a a round peg into a square a square hole and it's like it just no matter how you try to shove it in it's not gonna go in so sometimes it's just might as well go down a path that seems to work better for you\n",
            "Q: right that makes sense what's one of your most memorable experiences\n",
            "\n",
            "### Response:\n",
            "um i don't know if it's been <unaware> i mean i would say there's one that comes to mind which is um one time when i went out to visit my family in california on vacation and it was it was a big trip for me because i had never been there before so it was exciting and fun and interesting and i got to see friends who were there and we went to this concert which i thought was going to be fun but it turned\n",
            "\n",
            "================================================================================\n",
            "RESPONSE ONLY:\n",
            "================================================================================\n",
            "um i don't know if it's been <unaware> i mean i would say there's one that comes to mind which is um one time when i went out to visit my family in california on vacation and it was it was a big trip for me because i had never been there before so it was exciting and fun and interesting and i got to see friends who were there and we went to this concert which i thought was going to be fun but it turned\n",
            "\n",
            "Models unloaded from memory.\n"
          ]
        }
      ],
      "source": [
        "print(\"Loading final model...\")\n",
        "model, base_model = load_finetuned_model(model_name, tokenizer)\n",
        "\n",
        "# Load test dataset for evaluation\n",
        "print(\"\\nLoading test dataset for evaluation...\")\n",
        "# _, _, test_dataset = load_daic_data(tokenizer, should_create_csv=False, return_splits=True)\n",
        "\n",
        "try:\n",
        "    # Evaluate on test dataset\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"EVALUATING FINAL MODEL ON TEST DATASET\")\n",
        "    print(\"=\" * 80)\n",
        "    # test_metrics = evaluate_model_on_test(model, tokenizer, test_dataset)\n",
        "\n",
        "    # print(\"\\nTest Dataset Results:\")\n",
        "    # for key, value in test_metrics.items():\n",
        "    #     print(f\"  {key}: {value:.4f}\")\n",
        "\n",
        "    # Generate example response\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"GENERATING EXAMPLE RESPONSE\")\n",
        "    print(\"=\" * 80)\n",
        "    print(\"\\nGenerating response...\")\n",
        "    full_output = generate_response(model, tokenizer, request, max_new_tokens=100)\n",
        "    response_only = extract_response_only(full_output, request)\n",
        "\n",
        "    print(\"=\" * 80)\n",
        "    print(\"FULL OUTPUT:\")\n",
        "    print(\"=\" * 80)\n",
        "    print(full_output)\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"RESPONSE ONLY:\")\n",
        "    print(\"=\" * 80)\n",
        "    print(response_only)\n",
        "finally:\n",
        "    # Clean up models from memory\n",
        "    unload_model(model)\n",
        "    unload_model(base_model)\n",
        "    print(\"\\nModels unloaded from memory.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "kLAHxRHNAJBH",
        "outputId": "a6588682-f69c-4567-d977-6ca7c23a0dd9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading test dataset for checkpoint evaluation...\n",
            "After filtering empty answers - Train: 5953, Val: 1785, Test: 2588\n",
            "Train samples: 5953\n",
            "Validation samples: 1785\n",
            "Test samples: 2588\n",
            "Found 3 checkpoints. Testing each (memory-efficient mode)...\n",
            "\n",
            "[1/3] Testing checkpoint-400...\n",
            "Device set to use cuda:0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model set to eval mode for inference\n",
            "Generating with parameters: do_sample=True, temperature=0.7, top_p=0.9, top_k=50\n",
            "Input prompt length: 1697 characters\n",
            "Input token IDs shape: torch.Size([1, 470])\n",
            "Input token IDs (first 20): [1, 29871, 13, 3492, 526, 29537, 292, 263, 266, 1572, 412, 329, 293, 15593, 1546, 263, 6901, 1006, 29894, 15580]\n",
            "Generated token IDs shape: torch.Size([100])\n",
            "Generated token IDs (first 20): [29875, 4140, 474, 508, 1827, 393, 697, 310, 278, 1556, 26959, 519, 27482, 393, 474, 29915, 345, 750, 338, 746]\n",
            "Full generated text length: 2111 characters\n",
            "Full generated text (first 200 chars): \n",
            "You are analyzing a therapeutic interview between a virtual interviewer (Ellie) and a participant.\n",
            "The participant has a PHQ-8 score ranging from 0 (no depression) to 24 (severe depression). This par\n",
            "✓ checkpoint-400 completed\n",
            "  Memory freed after checkpoint-400\n",
            "\n",
            "[2/3] Testing checkpoint-600...\n",
            "Device set to use cuda:0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model set to eval mode for inference\n",
            "Generating with parameters: do_sample=True, temperature=0.7, top_p=0.9, top_k=50\n",
            "Input prompt length: 1697 characters\n",
            "Input token IDs shape: torch.Size([1, 470])\n",
            "Input token IDs (first 20): [1, 29871, 13, 3492, 526, 29537, 292, 263, 266, 1572, 412, 329, 293, 15593, 1546, 263, 6901, 1006, 29894, 15580]\n",
            "Generated token IDs shape: torch.Size([100])\n",
            "Generated token IDs (first 20): [398, 474, 1348, 278, 278, 931, 393, 474, 2355, 17285, 515, 590, 937, 4982, 1156, 318, 29882, 1023, 2440, 474]\n",
            "Full generated text length: 2139 characters\n",
            "Full generated text (first 200 chars): \n",
            "You are analyzing a therapeutic interview between a virtual interviewer (Ellie) and a participant.\n",
            "The participant has a PHQ-8 score ranging from 0 (no depression) to 24 (severe depression). This par\n",
            "✓ checkpoint-600 completed\n",
            "  Memory freed after checkpoint-600\n",
            "\n",
            "[3/3] Testing checkpoint-745...\n",
            "Device set to use cuda:0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model set to eval mode for inference\n",
            "Generating with parameters: do_sample=True, temperature=0.7, top_p=0.9, top_k=50\n",
            "Input prompt length: 1697 characters\n",
            "Input token IDs shape: torch.Size([1, 470])\n",
            "Input token IDs (first 20): [1, 29871, 13, 3492, 526, 29537, 292, 263, 266, 1572, 412, 329, 293, 15593, 1546, 263, 6901, 1006, 29894, 15580]\n",
            "Generated token IDs shape: torch.Size([100])\n",
            "Generated token IDs (first 20): [16099, 474, 508, 29915, 29873, 1348, 310, 385, 7271, 474, 3926, 750, 29871, 338, 697, 310, 278, 1556, 26959, 519]\n",
            "Full generated text length: 1965 characters\n",
            "Full generated text (first 200 chars): \n",
            "You are analyzing a therapeutic interview between a virtual interviewer (Ellie) and a participant.\n",
            "The participant has a PHQ-8 score ranging from 0 (no depression) to 24 (severe depression). This par\n",
            "✓ checkpoint-745 completed\n",
            "  Memory freed after checkpoint-745\n",
            "\n",
            "\n",
            "================================================================================\n",
            "CHECKPOINT COMPARISON\n",
            "================================================================================\n",
            "\n",
            "checkpoint-400:\n",
            "--------------------------------------------------------------------------------\n",
            "Generated Response:\n",
            "i guess i can say that one of the most memorable experiences that i've had is when we were living in kansas city and we had a friend that lived in kansas city and she came to visit us and we went out to see her and she was so excited about going to the zoo that she brought me along so we went and we saw all the animals and i was really fascinated by them and it was a good experience i remember that  <laughter>\n",
            "\n",
            "\n",
            "checkpoint-600:\n",
            "--------------------------------------------------------------------------------\n",
            "Generated Response:\n",
            "um i think the the time that i got fired from my first job after uh two years i got fired from the job i worked at before i got fired from my last job and the reason i got fired from both jobs was because i was not working hard enough and i was not getting good enough grades and i didn't understand why this was happening to me and i started thinking maybe it was just something i had to learn to do and maybe i wasn't capable of doing and i\n",
            "\n",
            "\n",
            "checkpoint-745:\n",
            "--------------------------------------------------------------------------------\n",
            "Generated Response:\n",
            "uh i can't think of an experience i ever had  is one of the most memorable experiences i've had that's also probably the least memorable ight ickle ickle ickle ickle ickle ickle ickle ickle ickle ickle ickle ickle ickle ickle ickle ickle ickle ickle ickle ickle ickle\n",
            "\n"
          ]
        }
      ],
      "source": [
        "def test_all_checkpoints(model_name, tokenizer, prompt, test_dataset=None, output_dir=\"./tiny_llama_instruction_tuned\"):\n",
        "    \"\"\"Test all checkpoint models and return results. Memory-efficient version.\n",
        "    Each model is loaded, tested, and immediately unloaded to save memory.\n",
        "\n",
        "    Args:\n",
        "        model_name: Base model name\n",
        "        tokenizer: Tokenizer instance\n",
        "        prompt: Prompt to test with\n",
        "        test_dataset: Optional test dataset for evaluation\n",
        "        output_dir: Directory containing checkpoints\n",
        "    \"\"\"\n",
        "    checkpoint_folders = sorted([\n",
        "        f for f in os.listdir(output_dir)\n",
        "        if f.startswith(\"checkpoint-\") and os.path.isdir(os.path.join(output_dir, f))\n",
        "    ])\n",
        "\n",
        "    if not checkpoint_folders:\n",
        "        print(\"No checkpoints found.\")\n",
        "        return {}\n",
        "\n",
        "    results = {}\n",
        "    stopping_criteria = create_stopping_criteria(tokenizer)\n",
        "\n",
        "    print(f\"Found {len(checkpoint_folders)} checkpoints. Testing each (memory-efficient mode)...\\n\")\n",
        "\n",
        "    for i, folder in enumerate(checkpoint_folders, 1):\n",
        "        checkpoint_path = os.path.join(output_dir, folder)\n",
        "        print(f\"[{i}/{len(checkpoint_folders)}] Testing {folder}...\")\n",
        "\n",
        "        model = None\n",
        "        base_model = None\n",
        "        try:\n",
        "            # Load model (returns both lora and base for cleanup)\n",
        "            model, base_model = load_finetuned_model(model_name, tokenizer, checkpoint_path)\n",
        "\n",
        "            # Generate response\n",
        "            full_output = generate_response(model, tokenizer, prompt, max_new_tokens=100, stopping_criteria=stopping_criteria)\n",
        "            response_only = extract_response_only(full_output, prompt)\n",
        "\n",
        "            # Evaluate on test dataset if provided\n",
        "            test_metrics = None\n",
        "            # if test_dataset is not None:\n",
        "            #     print(f\"  Evaluating {folder} on test dataset...\")\n",
        "            #     test_metrics = evaluate_model_on_test(model, tokenizer, test_dataset, output_dir)\n",
        "\n",
        "            results[folder] = {\n",
        "                \"full_output\": full_output,\n",
        "                \"response_only\": response_only,\n",
        "                \"test_metrics\": test_metrics\n",
        "            }\n",
        "\n",
        "            if test_metrics:\n",
        "                print(f\"  Test loss: {test_metrics.get('test_loss', 'N/A'):.4f}\")\n",
        "\n",
        "            print(f\"✓ {folder} completed\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"✗ Error testing {folder}: {e}\")\n",
        "            results[folder] = {\"error\": str(e)}\n",
        "        finally:\n",
        "            # Always unload models after each checkpoint to free memory\n",
        "            if model is not None:\n",
        "                unload_model(model)\n",
        "            if base_model is not None:\n",
        "                unload_model(base_model)\n",
        "            print(f\"  Memory freed after {folder}\\n\")\n",
        "\n",
        "    return results\n",
        "\n",
        "# Load test dataset for evaluation\n",
        "print(\"Loading test dataset for checkpoint evaluation...\")\n",
        "_, _, test_dataset = load_daic_data(tokenizer, should_create_csv=False, return_splits=True)\n",
        "\n",
        "# Test all checkpoints\n",
        "checkpoint_results = test_all_checkpoints(model_name, tokenizer, request, test_dataset=test_dataset)\n",
        "\n",
        "# Display results\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"CHECKPOINT COMPARISON\")\n",
        "print(\"=\" * 80)\n",
        "for checkpoint_name, result in checkpoint_results.items():\n",
        "    if \"error\" in result:\n",
        "        print(f\"\\n{checkpoint_name}: ERROR - {result['error']}\")\n",
        "    else:\n",
        "        print(f\"\\n{checkpoint_name}:\")\n",
        "        print(\"-\" * 80)\n",
        "\n",
        "        # Display test metrics if available\n",
        "        if result.get(\"test_metrics\"):\n",
        "            print(\"Test Metrics:\")\n",
        "            for key, value in result[\"test_metrics\"].items():\n",
        "                print(f\"  {key}: {value:.4f}\")\n",
        "            print()\n",
        "\n",
        "        # Display generated response\n",
        "        print(\"Generated Response:\")\n",
        "        print(result[\"response_only\"])\n",
        "        print()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h6l-qTPDOk1L",
        "outputId": "8b86aa72-8997-47b4-a9ba-af7ad92bb550"
      },
      "outputs": [],
      "source": [
        "!zip -r tiny_llama_instruction_tuned.zip /content/tiny_llama_instruction_tuned"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "01ad24b99b7b4e0bb99bb5dc6b0b88e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5198ded7b5004e3d88710742580da2ea",
            "max": 551,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bea913c7854e49519d15802c463f7b84",
            "value": 551
          }
        },
        "0a367ddbccd448ceb273811c51f2429f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0c2e6a131c334f808eba58cc5b873706": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "10f271c542cd4b48a675e5eece779288": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ad8d36a18ea942b59f804d0955cf446c",
            "placeholder": "​",
            "style": "IPY_MODEL_d3e81969a36f4300aec646c4ceaa07e0",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "1347cdbf28ca4b8283762144e80498e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d9bbfe584a814d51b0081c2f6d596c49",
            "placeholder": "​",
            "style": "IPY_MODEL_3d9d8fa5501c4b64bc3a56a9de0778b1",
            "value": "tokenizer.model: 100%"
          }
        },
        "21a132f36a3349608deb38af4a517237": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "25a9f9000f6941e48a3e289b6b163eed": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "294ca0b317fc40448615a93957456df3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "299e8325eeed4b27ad9eb9f1ac172c08": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2bc9b2e8fff044e5b99d4a6a0dba8c41": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a3315c72e2e645afb87719cb775bf9a4",
            "placeholder": "​",
            "style": "IPY_MODEL_d2fa92921d474e94880573aff86543e1",
            "value": "tokenizer.json: "
          }
        },
        "2da21a3d9db643a896fde03dcc4b7a3c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "30dc97bcc5e649bea85664945475255b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "36639d2f495943c286e751a3d0747780": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c000c7f314634e8c82523f77635f7d8b",
            "placeholder": "​",
            "style": "IPY_MODEL_6e2abba6ce6241e09f5688bff10965af",
            "value": " 2.20G/2.20G [00:16&lt;00:00, 295MB/s]"
          }
        },
        "382743f38f304d8a92b8f3be6ad8accb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3d9d8fa5501c4b64bc3a56a9de0778b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3e2708494e2a442fab323756f4614b96": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "44a9b8e66fa74581abac66e133b9b4dc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5198ded7b5004e3d88710742580da2ea": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "554c7cb87b894688a879e9439ea1cca6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "56e29613e37149be895a93c755baa783": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5e4f97d1db7c4501abc67840dd754fca",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d0dd00a7fb054c47a771f77e699ec106",
            "value": 1
          }
        },
        "56fb8ea45bae4768ae8b3935eb313437": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2bc9b2e8fff044e5b99d4a6a0dba8c41",
              "IPY_MODEL_f37660376c1843ac93929591e331a4c3",
              "IPY_MODEL_fd49caa736c043e3a013db50537f0d17"
            ],
            "layout": "IPY_MODEL_30dc97bcc5e649bea85664945475255b"
          }
        },
        "5bde957c7fa5405c82621755bb8e99a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cbc3f0acbd044f35a06fc5ec031b7a13",
            "placeholder": "​",
            "style": "IPY_MODEL_382743f38f304d8a92b8f3be6ad8accb",
            "value": "tokenizer_config.json: "
          }
        },
        "5c5515a6ec9249f69990aacca4e9d8cb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5db33535e9c4489bb6b6bb54cf6ade1b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e4f97d1db7c4501abc67840dd754fca": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "645bd2170fb348fd828fa58c5a5b93e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_be2da52036a0420eb063b2d4e8b03429",
            "placeholder": "​",
            "style": "IPY_MODEL_c0a0541adb0945fe9e9f83af88eff674",
            "value": "generation_config.json: 100%"
          }
        },
        "64ef082475b44a05b1681833bebfbf16": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6b09687d30da40ba910f1e8236e35292": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c4d97fd6f764f92a479a57880d55608": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_645bd2170fb348fd828fa58c5a5b93e4",
              "IPY_MODEL_c0d4ce502d7c4457a5aba8b7ac322a68",
              "IPY_MODEL_d20f8bc1859c4ef793a19522936a11f3"
            ],
            "layout": "IPY_MODEL_2da21a3d9db643a896fde03dcc4b7a3c"
          }
        },
        "6e2abba6ce6241e09f5688bff10965af": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "76ad1c63a59a4e0598d477d2378e2ff3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1347cdbf28ca4b8283762144e80498e4",
              "IPY_MODEL_92e4f2b6b4f4472c811dc2dfa88fb073",
              "IPY_MODEL_b09b7e73032e44a0a676229c752264ce"
            ],
            "layout": "IPY_MODEL_cfef698890dd4efdae358c5cb449b480"
          }
        },
        "780e75ef9d614625bc4f7734482deeed": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_44a9b8e66fa74581abac66e133b9b4dc",
            "placeholder": "​",
            "style": "IPY_MODEL_cc0121c3f82e42fa8174e86224eace37",
            "value": "model.safetensors: 100%"
          }
        },
        "7af402bc8f6342f483bb73abe8568439": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5db33535e9c4489bb6b6bb54cf6ade1b",
            "max": 2200119864,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ee0b9614209144b8ab038863d3537e0c",
            "value": 2200119864
          }
        },
        "81c7089382194cb69327a673fade34d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_21a132f36a3349608deb38af4a517237",
            "placeholder": "​",
            "style": "IPY_MODEL_dd4f5eefc717494b81ca9702dda23379",
            "value": " 608/608 [00:00&lt;00:00, 77.6kB/s]"
          }
        },
        "849a279ec86c4945aa042577678d3d73": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a0e91409876048698b925cf8e9738bf7",
              "IPY_MODEL_c3e93fd7949440329b7f12e5d829e199",
              "IPY_MODEL_81c7089382194cb69327a673fade34d6"
            ],
            "layout": "IPY_MODEL_af0a329bcaf84e7995c0700a83862301"
          }
        },
        "864b0312be704218a0d67ffa3f668296": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "89570a3fce394ddd81c5a5eb1f2c7cbb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_294ca0b317fc40448615a93957456df3",
            "placeholder": "​",
            "style": "IPY_MODEL_bacc327e99bd4030bf721d40a2270178",
            "value": " 1.29k/? [00:00&lt;00:00, 123kB/s]"
          }
        },
        "907923f82c0e4535a40b064fabd47a56": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "90bf8182e8694d52822c36735a7015ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_780e75ef9d614625bc4f7734482deeed",
              "IPY_MODEL_7af402bc8f6342f483bb73abe8568439",
              "IPY_MODEL_36639d2f495943c286e751a3d0747780"
            ],
            "layout": "IPY_MODEL_5c5515a6ec9249f69990aacca4e9d8cb"
          }
        },
        "92e4f2b6b4f4472c811dc2dfa88fb073": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d94ccb2e46a34fc497b5a0ea7094b555",
            "max": 499723,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_864b0312be704218a0d67ffa3f668296",
            "value": 499723
          }
        },
        "a0e91409876048698b925cf8e9738bf7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6b09687d30da40ba910f1e8236e35292",
            "placeholder": "​",
            "style": "IPY_MODEL_c8cbf8ff7c5b40de9cdeb919f1841b59",
            "value": "config.json: 100%"
          }
        },
        "a3315c72e2e645afb87719cb775bf9a4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ad8d36a18ea942b59f804d0955cf446c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af0a329bcaf84e7995c0700a83862301": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b09b7e73032e44a0a676229c752264ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b6dcc7166be6428396e06b1de5a22fb0",
            "placeholder": "​",
            "style": "IPY_MODEL_3e2708494e2a442fab323756f4614b96",
            "value": " 500k/500k [00:00&lt;00:00, 1.05MB/s]"
          }
        },
        "b6dcc7166be6428396e06b1de5a22fb0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b73f30ac75324c878fd202825ff051b0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b78f81b677764140ac6e8f91b93cd931": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bacc327e99bd4030bf721d40a2270178": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "be2da52036a0420eb063b2d4e8b03429": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bea913c7854e49519d15802c463f7b84": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c000c7f314634e8c82523f77635f7d8b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c0a0541adb0945fe9e9f83af88eff674": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c0d4ce502d7c4457a5aba8b7ac322a68": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0c2e6a131c334f808eba58cc5b873706",
            "max": 124,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0a367ddbccd448ceb273811c51f2429f",
            "value": 124
          }
        },
        "c3e93fd7949440329b7f12e5d829e199": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cbe0398706aa44209fc058fbdcb030d0",
            "max": 608,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_554c7cb87b894688a879e9439ea1cca6",
            "value": 608
          }
        },
        "c40b888c76fb44bb943ac514fe6f5341": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c66abb85c5d745509303452122f39834": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_64ef082475b44a05b1681833bebfbf16",
            "placeholder": "​",
            "style": "IPY_MODEL_c40b888c76fb44bb943ac514fe6f5341",
            "value": " 551/551 [00:00&lt;00:00, 52.7kB/s]"
          }
        },
        "c8cbf8ff7c5b40de9cdeb919f1841b59": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cbc3f0acbd044f35a06fc5ec031b7a13": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cbe0398706aa44209fc058fbdcb030d0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cc0121c3f82e42fa8174e86224eace37": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cfef698890dd4efdae358c5cb449b480": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d0dd00a7fb054c47a771f77e699ec106": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d20f8bc1859c4ef793a19522936a11f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ebf6a692195440f6bf1a0d91cb24dd8f",
            "placeholder": "​",
            "style": "IPY_MODEL_ee7f858281e24e228b9302eeffcd2712",
            "value": " 124/124 [00:00&lt;00:00, 7.03kB/s]"
          }
        },
        "d2fa92921d474e94880573aff86543e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d3e81969a36f4300aec646c4ceaa07e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d8d0c877b25f4353aab7329825eb4436": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_10f271c542cd4b48a675e5eece779288",
              "IPY_MODEL_01ad24b99b7b4e0bb99bb5dc6b0b88e1",
              "IPY_MODEL_c66abb85c5d745509303452122f39834"
            ],
            "layout": "IPY_MODEL_25a9f9000f6941e48a3e289b6b163eed"
          }
        },
        "d94ccb2e46a34fc497b5a0ea7094b555": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d9bbfe584a814d51b0081c2f6d596c49": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd4f5eefc717494b81ca9702dda23379": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e22024bc36d241f1ba4187ea75d20d9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5bde957c7fa5405c82621755bb8e99a5",
              "IPY_MODEL_56e29613e37149be895a93c755baa783",
              "IPY_MODEL_89570a3fce394ddd81c5a5eb1f2c7cbb"
            ],
            "layout": "IPY_MODEL_b73f30ac75324c878fd202825ff051b0"
          }
        },
        "ebf6a692195440f6bf1a0d91cb24dd8f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee0b9614209144b8ab038863d3537e0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ee7f858281e24e228b9302eeffcd2712": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f37660376c1843ac93929591e331a4c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f8f9bddf00604b35964c9a132e2119a1",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_299e8325eeed4b27ad9eb9f1ac172c08",
            "value": 1
          }
        },
        "f8f9bddf00604b35964c9a132e2119a1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "fd49caa736c043e3a013db50537f0d17": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_907923f82c0e4535a40b064fabd47a56",
            "placeholder": "​",
            "style": "IPY_MODEL_b78f81b677764140ac6e8f91b93cd931",
            "value": " 1.84M/? [00:00&lt;00:00, 35.6MB/s]"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
